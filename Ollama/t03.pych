import os
from elasticsearch import Elasticsearch, helpers
from PyPDF2 import PdfReader
from sentence_transformers import SentenceTransformer
import requests
import json
from colorama import Fore, Style, init

# Inicializa o colorama para Windows
init(autoreset=True)

# ConfiguraÃ§Ãµes do ElasticSearch
ELASTIC_URL = 'http://143.54.112.91:9200'
INDEX_NAME = 'brapci3.3'

# InicializaÃ§Ã£o do Elasticsearch
es = Elasticsearch(ELASTIC_URL)


# FunÃ§Ã£o para buscar documentos relevantes
def search_documents(query, top_k=3):
    response = es.search(index=INDEX_NAME,
                         body={
                             "query": {
                                 "bool": {
                                     "must": [{
                                         "match": {
                                             "full": "'altmetria'"
                                         }
                                     }]
                                 }
                             },
                             "size": "100",
                             "from": 0
                         })
    return [hit['_source']['full'] for hit in response['hits']['hits']]


# FunÃ§Ã£o para gerar resposta usando o OLLAMA API
def generate_response_with_ollama(context, question):
    prompt = f"Baseado nos seguintes documentos:\n{context}\n\nResponda Ã  seguinte pergunta:\n{question}"

    response = requests.post(
        'http://localhost:11434/api/generate',
        headers={'Content-Type': 'application/json'},
        data=json.dumps({
            "model": "llama3.1",  # Certifique-se de que o modelo estÃ¡ correto
            "prompt": prompt,
            "temperature": 0,
            "stream":
            False  # Tente definir como False se o OLLAMA estiver retornando respostas tokenizadas
        }))

    try:
        print(Fore.CYAN + "Resposta bruta da API:", response.text)
        response_json = response.json()

        # Tentar pegar o campo correto da resposta
        if 'response' in response_json:
            return response_json['response']
        elif 'text' in response_json:
            return response_json['text']
        else:
            return f"Resposta inesperada: {response_json}"

    except json.JSONDecodeError as e:
        return f"Erro de decodificaÃ§Ã£o JSON: {e}\nResposta bruta da API: {response.text}"


# Pipeline completo de RAG
def rag_pipeline(pdf_folder, question):
    # RecuperaÃ§Ã£o de documentos relevantes
    print("===", question)
    retrieved_docs = search_documents(question)

    # GeraÃ§Ã£o da resposta com OLLAMA
    context = "\n".join(retrieved_docs)
    response = generate_response_with_ollama(context, question)

    return retrieved_docs, response


# Uso do pipeline
pdf_folder_path = 'docs'
pergunta = 'O que Ã© a Ã¡rea de Estudos Metricos da InformaÃ§Ã£o'
pergunta = 'Qual a relaÃ§Ã£o entre Estudos Metricos da InformaÃ§Ã£o e a Altmetria'

retrieved_docs, resposta = rag_pipeline(pdf_folder_path, pergunta)

# ExibiÃ§Ã£o organizada
print(Fore.GREEN + "\n" + "=" * 50)
print(Fore.CYAN + "ðŸ“š **Documentos Utilizados na Resposta** ðŸ“š")
print(Fore.GREEN + "=" * 50)
for idx, doc in enumerate(retrieved_docs, 1):
    print(f"{idx}. {doc[:80]}..."
          )  # Mostra os primeiros 300 caracteres de cada documento

print(Fore.GREEN + "\n" + "=" * 50)
print(Fore.CYAN + "ðŸ“„ **Resposta Gerada com Base nos Documentos PDF** ðŸ“„")
print(Fore.GREEN + "=" * 50)
print(Fore.YELLOW + resposta.strip())
print(Fore.GREEN + "=" * 50)
