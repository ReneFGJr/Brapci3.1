import os
from elasticsearch import Elasticsearch, helpers
from PyPDF2 import PdfReader
from sentence_transformers import SentenceTransformer
import requests
import json
from colorama import Fore, Style, init

# Inicializa o colorama para Windows
init(autoreset=True)

# ConfiguraÃ§Ãµes do ElasticSearch
ELASTIC_URL = 'http://143.54.112.91:9200'
INDEX_NAME = 'pdf_documents'

# InicializaÃ§Ã£o do Elasticsearch
es = Elasticsearch(ELASTIC_URL)

# FunÃ§Ã£o para buscar documentos relevantes
def search_documents(query, top_k=3):
    response = es.search(
        index=INDEX_NAME,
        body={
            "query": {
                "match": {
                    "content": query
                }
            },
            "size": top_k
        }
    )
    return [hit['_source']['content'] for hit in response['hits']['hits']]

# FunÃ§Ã£o para gerar resposta usando o OLLAMA API
def generate_response_with_ollama(context, question):
    prompt = f"Baseado nos seguintes documentos:\n{context}\n\nResponda Ã  seguinte pergunta:\n{question}"

    response = requests.post(
        'http://localhost:11434/api/generate',
        headers={'Content-Type': 'application/json'},
        data=json.dumps({
            "model": "llama3.1",  # Certifique-se de que o modelo estÃ¡ correto
            "prompt": prompt,
            "temperature": 0,
            "stream": False  # Tente definir como False se o OLLAMA estiver retornando respostas tokenizadas
        })
    )

    try:
        print(Fore.CYAN + "Resposta bruta da API:", response.text)
        response_json = response.json()

        # Tentar pegar o campo correto da resposta
        if 'response' in response_json:
            return response_json['response']
        elif 'text' in response_json:
            return response_json['text']
        else:
            return f"Resposta inesperada: {response_json}"

    except json.JSONDecodeError as e:
        return f"Erro de decodificaÃ§Ã£o JSON: {e}\nResposta bruta da API: {response.text}"


# Pipeline completo de RAG
def rag_pipeline(pdf_folder, question):
    # RecuperaÃ§Ã£o de documentos relevantes
    retrieved_docs = search_documents(question)

    # GeraÃ§Ã£o da resposta com OLLAMA
    context = "\n".join(retrieved_docs)
    response = generate_response_with_ollama(context, question)

    return retrieved_docs, response

# Uso do pipeline
pdf_folder_path = 'docs'
pergunta = 'O que Ã© o VUFIND e quem densenvolvel o software? Responda de forma breve, em uma linha.'
pergunta = 'Quais os outros software do tipo que concorrem com o VU FIND.'
pergunta = 'Qual a vantagem de se utilizar o vuFIND?'
pergunta = 'O que os representantes da NIS e da ODI desenvolveram?'

retrieved_docs, resposta = rag_pipeline(pdf_folder_path, pergunta)

# ExibiÃ§Ã£o organizada
print(Fore.GREEN + "\n" + "="*50)
print(Fore.CYAN + "ðŸ“š **Documentos Utilizados na Resposta** ðŸ“š")
print(Fore.GREEN + "="*50)
for idx, doc in enumerate(retrieved_docs, 1):
    print(f"{idx}. {doc[:10]}...")  # Mostra os primeiros 300 caracteres de cada documento

print(Fore.GREEN + "\n" + "="*50)
print(Fore.CYAN + "ðŸ“„ **Resposta Gerada com Base nos Documentos PDF** ðŸ“„")
print(Fore.GREEN + "="*50)
print(Fore.YELLOW + resposta.strip())
print(Fore.GREEN + "="*50)
