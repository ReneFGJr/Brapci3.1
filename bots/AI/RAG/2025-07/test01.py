from langchain.text_splitter import CharacterTextSplitter
from langchain.chains import RetrievalQA

# NOVOS IMPORTS
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import Chroma
from langchain_ollama.embeddings import OllamaEmbeddings
from langchain_ollama import ChatOllama

# Passo 1: Criar documento
with open("organizacao_conhecimento.txt", "w", encoding="utf-8") as f:
    f.write("""
    Organiza√ß√£o do Conhecimento √© um campo da Ci√™ncia da Informa√ß√£o que estuda os m√©todos de representa√ß√£o, estrutura√ß√£o e recupera√ß√£o da informa√ß√£o.
    Ela abrange √°reas como classifica√ß√£o, indexa√ß√£o, cataloga√ß√£o, taxonomias e ontologias. Seu objetivo √© facilitar o acesso √† informa√ß√£o,
    permitindo que usu√°rios encontrem e compreendam conte√∫dos relevantes. A Organiza√ß√£o do Conhecimento √© fundamental em bibliotecas, arquivos, museus e bases digitais.
    """)

# Passo 2: Carregar e dividir
loader = TextLoader("organizacao_conhecimento.txt", encoding="utf-8")
docs = loader.load()
splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)
texts = splitter.split_documents(docs)

# Passo 3: Embeddings + Chroma
embeddings = OllamaEmbeddings(model="llama3.1")
db = Chroma.from_documents(texts, embeddings, persist_directory="./db_rag")
db.persist()

# Passo 4: Recupera√ß√£o e QA
retriever = db.as_retriever(search_kwargs={"k": 2})
llm = ChatOllama(model="llama3.1")
qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)

# Passo 5: Pergunta
query = "O que √© organiza√ß√£o do conhecimento?"
resposta = qa.invoke({"query": query})

# Mostrar resposta
print("üîç Resposta:", resposta["result"])

# Mostrar fontes (opcional)
for doc in resposta["source_documents"]:
    print("\nüìÑ Fonte:")
    print(doc.page_content.strip())
